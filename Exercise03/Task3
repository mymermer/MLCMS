import tensorflow as tf
import tensorflow_probability as tfp
import numpy as np 
import matplotlib.pyplot as plt
import pandas as pd

# Load and preprocess MNIST data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()


# Normalize pixel values between 0 and 1 (the typical range for grayscale images pixel values is between 0 and 255) 
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# Reshape images to a flattened format (a single vector):  each image is initially represented as a 28x28 array of pixel values (2D array). 
x_train = x_train.reshape(x_train.shape[0], -1)
x_test = x_test.reshape(x_test.shape[0], -1)

"""

# Visualisation of the first six images in x_train
plt.figure(figsize=(8, 2))
for i in range(6):
    plt.subplot(1, 6, i+1)
    plt.imshow(x_train[i].reshape(28, 28), cmap="gray_r") # resizes the images to 28x28 pixels
    plt.title('Label = %d' % y_train[i], fontsize=14) # displays the images along with their corresponding labels from y_train
    plt.axis("off")
plt.tight_layout()
plt.show()


# Visualisation of the shapes of the training and test data
print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)
print('y_train shape:', y_train.shape)
print('y_test shape:', y_test.shape)

print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

"""


data_shape = 784 # shape of the data (28x28=784)

latent_dim = 2 # dimension of the latent space : to be changed for the last question of task 3

batch_size = 128 # batch size for training

#create encoder
inputs = tf.keras.Input(shape=data_shape)
x = tf.keras.layers.Dense(256, activation='relu')(inputs)
x = tf.keras.layers.Dense(256, activation='relu')(x)

# Mean and standard deviation outputs for the approximate posterior qφ(z|x)
z_mean = tf.keras.layers.Dense(latent_dim)(x)
z_log_var = tf.keras.layers.Dense(latent_dim)(x) # or tf.keras.layers.Activation('softplus')(z_log_var) -> positivity insurance


def sampling(args):
    """
    Sampling from the latent multivariate diagonal standard normal distribution as prior p(z).
    Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.
        Also referred to as "Reparameterization trick".
    """
    z_mean, z_log_var = args
    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim)) #shape=(batch_size, latent_dim)=z_mean.shape
    return z_mean + tf.exp(0.5*z_log_var) * epsilon

z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var]) 

encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')

# Create decoder
latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')
x = tf.keras.layers.Dense(256, activation='relu')(latent_inputs)
x = tf.keras.layers.Dense(256, activation='relu')(x)

outputs_mean = tf.keras.layers.Dense(data_shape, activation='sigmoid')(x) #Outputs only the mean of likelihood pθ(x|z)

# Implement standard deviation as a trainable variable of the model
decoder_stddev = tf.Variable(tf.ones(shape=(data_shape,), dtype=tf.float32), name='decoder_stddev') # or tf.Variable(initial_value=1.0, trainable=True, dtype=tf.float32, name='decoder_stddev') for a single-floating point ?
decoded_with_stddev = tf.keras.layers.Lambda(lambda x: x[0] * x[1])([outputs_mean, decoder_stddev])

decoder = tf.keras.Model(latent_inputs, decoded_with_stddev, name='decoder')

# Create VAE
outputs = decoder(encoder(inputs)[2])
vae = tf.keras.Model(inputs, outputs, name='vae')


# Define the loss function
    # Reconstruction loss : binary cross-entropy between the input and output
reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, outputs)
reconstruction_loss *= data_shape
reconstruction_loss += 0.5 * tf.reduce_sum(tf.square(outputs - inputs) / tf.square(decoder_stddev) + tf.math.log(tf.square(decoder_stddev))) #include the standard deviation term 

    # KL divergence loss : KL divergence between the approximate posterior qφ(z|x) and the prior p(z)
kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
kl_loss = tf.reduce_sum(kl_loss, axis=-1)
kl_loss *= -0.5

    # Total loss : sum of the reconstruction loss and the KL divergence loss
vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)
vae.add_loss(vae_loss)

    # Compile the model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
vae.compile(optimizer=optimizer)


# Train the VAE and collect loss values at specific epochs

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True) # Stop training when the validation loss is no longer improving ie convergence is reached


history = vae.fit(
    x_train,
    epochs=100,
    batch_size=batch_size,
    validation_data=(x_test, None),
    verbose=1,
    callbacks=[early_stopping]
)

"""
# Plotting the loss curve (training + test set), i.e., epoch vs. −LELBO (Q4)

    #Extract loss values
train_loss = history.history['loss']
val_loss = history.history['val_loss']

    #Plot loss curve
epochs = range(1, len(train_loss) + 1)
plt.plot(epochs, train_loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('-ELBO')
plt.title('Loss Curve')
plt.legend()
plt.show()
"""

# Plotting the different figures for the specified epochs (Q3)

epochs_list = [1, 5, 25, 50]  # Epochs for experiments
epochs_to_save = set(epochs_list)
epochs_to_save.add(0)  # Save state after the 1st epoch

for epoch in range(1,101) : # Save the state of the model at the specified epochs

    if epoch in epochs_list and epoch <= early_stopping.stopped_epoch : 

        # Plotting the latent vector representation of a few batches of data : encode the test set and mark the different classes 
        x_test_encoded = encoder.predict(x_test, batch_size=batch_size)[2]

        plt.figure(figsize=(8, 8))
        scatter = plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap='viridis', alpha=0.7)
        plt.colorbar(scatter, label='Digits class')
        plt.title(f"Epoch {epoch} - Latent Vector Representation of Test Set with Class Labels")
        plt.show()

        # Plotting some of the reconstructed digits from the latent space (15) and the corresponding original ones 
        reconstructed_images = vae.predict(x_test[:15]) # Generate 15 reconstructed images

        plt.figure(figsize=(15, 4))

        for i in range(15):
            # Original images
            ax = plt.subplot(2, 15, i + 1)
            plt.imshow(x_test[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)

            # Reconstructed images
            ax = plt.subplot(2, 15, i + 16)
            plt.imshow(reconstructed_images[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.suptitle(f"Epoch {epoch} - Original and Reconstructed Digits")
        plt.show()


        # Plotting some of the generated digits (15) 
        random_samples = np.random.normal(size=(15, latent_dim)) # Generate 15 samples from the prior distribution
        generated_images = decoder.predict(random_samples) # Generate 15 generated images, decoded from the latent space

        plt.figure(figsize=(10, 4))
        for i in range(15):
            ax = plt.subplot(3, 5, i + 1)
            plt.imshow(generated_images[i].reshape(28, 28))
            plt.gray()
            ax.get_xaxis().set_visible(False)
            ax.get_yaxis().set_visible(False)
        plt.suptitle(f"Epoch {epoch} - Generated Digits")
        plt.show()

    else : # Stop the loop when the model stops training (convergence is reached)
        if early_stopping.stopped_epoch != 0:
                print("Convergence reached at epoch", early_stopping.stopped_epoch + 1)
                print("Training stopped at :", epoch)
                break

    
            



import tensorflow as tf
import tensorflow_probability as tfp
import numpy as np 
import matplotlib.pyplot as plt
import pandas as pd

# Load and preprocess MNIST data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()


# Normalize pixel values between 0 and 1 : xhen normalizing pixel values, the typical range for pixel values in images is between 0 and 255 
# for grayscale images (0 being black and 255 being white). 
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# Reshape images to a flattened format :  each image is initially represented as a 28x28 array of pixel values (2D array). 
# To feed this data into a neural network, it needs to be converted into a single vector with 784 (28x28) elements (1D array).
x_train = x_train.reshape(x_train.shape[0], -1)
x_test = x_test.reshape(x_test.shape[0], -1)

"""
# Visualisation of the first six images in x_train
plt.figure(figsize=(8, 2))
for i in range(6):
    plt.subplot(1, 6, i+1)
    plt.imshow(x_train[i].reshape(28, 28), cmap="gray_r") # resizes the images to 28x28 pixels
    plt.title('Label = %d' % y_train[i], fontsize=14) # displays the images along with their corresponding labels from y_train
    plt.axis("off")
plt.tight_layout()
plt.show()


# Visualisation of the shapes of the training and test data
print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)
print('y_train shape:', y_train.shape)
print('y_test shape:', y_test.shape)

print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

"""


data_shape = 784 # shape of the data (28x28=784)

latent_dim = 2 # dimension of the latent space, it will be changes for the last question of task 3

batch_size = 128 # batch size for training

#create encoder
inputs = tf.keras.Input(shape=data_shape)
x = tf.keras.layers.Dense(256, activation='relu')(inputs)
x = tf.keras.layers.Dense(256, activation='relu')(x)

# Mean and standard deviation outputs for the approximate posterior qφ(z|x)
z_mean = tf.keras.layers.Dense(latent_dim)(x)
z_log_var = tf.keras.layers.Dense(latent_dim)(x)

# Reparameterization trick for sampling from the distribution
def sampling(args):
    z_mean, z_log_var = args
    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim)) #tf.random.normal(shape=(tf.shape(z_mean)[0], latent_dim), mean=0, stddev=stddev)
    return z_mean + tf.exp(0.5*z_log_var) * epsilon

z = tf.keras.layers.Lambda(sampling)([z_mean, z_log_var]) # ou layers.Lambda(sampling)([z_mean, z_log_var]) , output_shape=(latent_dim,)

encoder = tf.keras.Model(inputs, [z_mean, z_log_var, z], name='encoder')

#create decoder
latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')
x = tf.keras.layers.Dense(256, activation='relu')(latent_inputs)
x = tf.keras.layers.Dense(256, activation='relu')(x)

# Output only the mean of pθ(x|z)
outputs = tf.keras.layers.Dense(data_shape, activation='sigmoid')(x)

# Implement standard deviation as a trainable variable of the model
decoder_stddev = tf.Variable(tf.ones(data_shape), dtype=tf.float32, name='decoder_stddev')
decoder = tf.keras.Model(latent_inputs, outputs, name='decoder')

#create VAE
outputs = decoder(encoder(inputs)[2])
vae = tf.keras.Model(inputs, outputs, name='vae')


#define the loss function
reconstruction_loss = tf.keras.losses.binary_crossentropy(inputs, outputs)
reconstruction_loss *= data_shape
kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)
kl_loss = tf.reduce_sum(kl_loss, axis=-1)
kl_loss *= -0.5

vae_loss = tf.reduce_mean(reconstruction_loss + kl_loss)
vae.add_loss(vae_loss)

optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
vae.compile(optimizer=optimizer)


# Train the VAE and collect loss values
history = vae.fit(x_train, x_train, epochs=25, batch_size=batch_size, validation_data=(x_test, x_test))




""" Plotting the loss curve (test set), i.e., epoch vs. −LELBO"""

# Extract loss values
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot loss curve
epochs = range(1, len(train_loss) + 1)
plt.plot(epochs, train_loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('-ELBO')
plt.title('Negative Evidence Lower Bound (ELBO)')
plt.legend()
plt.show()




""" Plotting the latent vector representation of a few batches of data : encode the test set and mark the different classes """

x_test_encoded = encoder.predict(x_test, batch_size=batch_size)[2]
plt.figure(figsize=(6, 6))
plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)
plt.colorbar()
plt.show()



""" Visualisation of some of the reconstructed digits from the latent space (15) and the corresponding original ones """

# Generate reconstructed images
reconstructed_images = vae.predict(x_test)

# Plot original and reconstructed images
n = 15  # Number of digits to display
plt.figure(figsize=(10, 4))

for i in range(n):
    # Original images
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Reconstructed images
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(reconstructed_images[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()




""" Visualisation of some of the generated digits (15) """

# Generate samples from the prior distribution
random_samples = np.random.normal(size=(15, latent_dim))

# Decode random samples
generated_images = decoder.predict(random_samples)

# Plot generated images
plt.figure(figsize=(10, 4))

for i in range(15):
    ax = plt.subplot(3, 5, i + 1)
    plt.imshow(generated_images[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()


